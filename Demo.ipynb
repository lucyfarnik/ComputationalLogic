{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0vSCAwPAleW"
      },
      "source": [
        "# Demo for Computational Logic for Artificial Intelligence Coursework\n",
        "This Colab notebook, created by Lucy Farnik as part of the Computational Logic for Artificial Intelligence class, demonstrated the extended reasoning abilities of [Prolexa](https://github.com/simply-logical/ComputationalLogic) to handle negation and existential qunatification. Additionally, in the second section I explain my work-in-progress attempt to fully refactor Prolexa's grammar in order to handle complex conjunctive and disjunctive statements.\n",
        "\n",
        "The codebase I'll be using can be found in my [GitHub repo](https://github.com/lucyfarnik/ComputationalLogic/tree/prolexa-plus). The work-in-progress refactoring code can be found on the [`multi-meaning` branch](https://github.com/lucyfarnik/ComputationalLogic/tree/multi-meaning) in the same repository.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hij-_4uHAzIj"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDY7hKs490UH",
        "outputId": "52e947d8-f571-406f-f97d-457ec077a85c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting templates from packages: 100%\n"
          ]
        }
      ],
      "source": [
        "!apt-get install swi-prolog -qqq > /dev/null\n",
        "!yes | pip install git+https://github.com/lucyfarnik/ComputationalLogic/ -qqq > /dev/null\n",
        "from pyswip import Prolog\n",
        "import prolexa.meta_grammar as meta\n",
        "\n",
        "pl = Prolog()\n",
        "meta.reset_grammar()\n",
        "meta.initialise_prolexa(pl)\n",
        "\n",
        "def prolexa(utternance):\n",
        "    print(\"User: \", utternance)\n",
        "    print(\"Assistant: \", meta.standardised_query(pl, utternance)[0]['Output'], \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Negation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prolexa can now handle reasoning such as\n",
        "> donald is not happy; every teacher is happy; therefore donald is not a teacher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementation of negation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Negation is implemented using the new `not()` predicate, for instance \"donald is not happy\" is stored as `(not(happy(donald)):-true)`.\n",
        "\n",
        "The following clauses were added to the grammar to make this work:\n",
        "```prolog\n",
        "pred(teacher, 1,[n/teacher]).\n",
        "pred(happy,   1,[a/happy]).\n",
        "proper_noun(s,donald) --> [donald].\n",
        "\n",
        "sentence1(C) --> determiner(N,M1,X=>not(H),C),noun(N,M1),verb_phrase(N,not(X=>H)).\n",
        "sentence1([(not(L):-true)]) --> proper_noun(N,X),verb_phrase(N,not(X=>L)).\n",
        "\n",
        "verb_phrase(s,not(M)) --> [is,not],property(s,M).\n",
        "verb_phrase(p,not(M)) --> [are,not],property(p,M).\n",
        "verb_phrase(s,not(M)) --> [does,not],iverb(p,M).\n",
        "verb_phrase(p,not(M)) --> [do,not],iverb(p,M).\n",
        "\n",
        "question1(not(Q)) --> [is], proper_noun(N,X),[not],property(N,X=>Q).\n",
        "question1(not(Q)) --> [does],proper_noun(_,X),[not],verb_phrase(_,X=>Q).\n",
        "```\n",
        "\n",
        "This was complemented by adding modus tollens to `prolexa_engine`:\n",
        "```prolog\n",
        "prove_rb(not(A),Rulebase,P0,P) :- % modus tollens\n",
        "\tfind_clause((B:-A),Rule,Rulebase),\n",
        "\tprove_rb(not(B),Rulebase,[p(A,Rule)|P0],P).\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo of negation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prolexa(\"forget everything\")\n",
        "prolexa(\"donald is not happy\")\n",
        "prolexa(\"every teacher is happy\")\n",
        "prolexa(\"explain why donald is not a teacher\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Existential quantification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prolexa can do reasoning such as\n",
        "> every genius wins; some humans are geniuses; therefore some humans win\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Implementation of existential quantification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The implementation of existential quantification is based on Skolemisation,\n",
        "explained in [Chapter 2.5 of Simply Logical textbook](https://book.simply-logical.space/src/text/1_part_i/2.5.html).\n",
        "\"some humans are geniuses\" gets translated to `(human(sk):-true),(genius(sk):-true)`,\n",
        "where `sk` is a Skolem constant.\n",
        "\n",
        "This required uncommenting out the following lines in `prolexa_grammar`:\n",
        "```prolog\n",
        "determiner(p,X=>B,X=>H,[(H:-B)]) --> [].\n",
        "determiner(p, sk=>H1, sk=>H2, [(H1:-true),(H2 :- true)]) -->[some].\n",
        "\n",
        "question1((Q1,Q2)) --> [are,some],noun(p,sk=>Q1), property(p,sk=>Q2).\n",
        "```\n",
        "as well as adding the following lines:\n",
        "```prolog\n",
        "pred(genius,  1,[n/genius]).\n",
        "\n",
        "% most of this clause is already in the original codebase\n",
        "noun_s2p(Noun_s,Noun_p):-\n",
        "\t( Noun_s=woman -> Noun_p=women\n",
        "\t; Noun_s=man -> Noun_p=men\n",
        "\t; Noun_s=genius -> Noun_p=geniuses % I only added this line\n",
        "\t; atom_concat(Noun_s,s,Noun_p)\n",
        "\t).\n",
        "\n",
        "question1((Q1,Q2)) --> [do,some],noun(p,sk=>Q1), verb_phrase(p,sk=>Q2).\n",
        "\n",
        "command(g(explain_question((Q1,Q2),_,Answer),Answer)) --> [explain,why],sentence1([(Q1:-true),(Q2:-true)]).\n",
        "```\n",
        "\n",
        "Making this work with `prolexa_engine` required adding support for a sentence\n",
        "being translated into 2 conjunctive clauses. First, this meant extending\n",
        "`prove_rb` with the following code, which simply states that to prove a conjunction,\n",
        "one must prove both its parts, and that the proof of the conjunction simply consists\n",
        "of the combination of the proofs required for each part:\n",
        "```prolog\n",
        "prove_rb((A,B),Rulebase,P0,P):-!,\n",
        "\tprove_rb(A,Rulebase,P0,P1),\n",
        "\tprove_rb(B,Rulebase,P1,P).\n",
        "```\n",
        "\n",
        "Next, it was necessary to extend `find_clause` to enable it to match clauses\n",
        "like `human(sk):-X` with rules like `[(human(sk):-true),(genius(sk):-true)]`:\n",
        "```prolog\n",
        "find_clause(Clause,[Rule1,Rule2],[[Rule1,Rule2]|_Rules]):-\n",
        "\tcopy_term(Rule1,Clause) ; copy_term(Rule2,Clause).\n",
        "```\n",
        "\n",
        "Lastly, I also modified `explain_question` to take into account the fact that\n",
        "a query can be conjunctive.\n",
        "\n",
        "```prolog\n",
        "explain_question(Query,SessionId,Answer):-\n",
        "\tfindall(R,prolexa:stored_rule(SessionId,R),Rulebase),\n",
        "\t( prove_rb(Query,Rulebase,[],Proof) ->\n",
        "\t\tmaplist(pstep2message,Proof,Msg),\n",
        "\t\t(\n",
        "\t\t\tQuery = (Q1,Q2), phrase(sentence1([(Q1:-true),(Q2:-true)]),L)\n",
        "\t\t\t; Query \\= (_,_), phrase(sentence1([(Query:-true)]),L)\n",
        "\t\t),\n",
        "\t\tatomic_list_concat([therefore|L],\" \",Last),\n",
        "\t\tappend(Msg,[Last],Messages),\n",
        "\t\tatomic_list_concat(Messages,\"; \",Answer)\n",
        "\t; Answer = 'Sorry, I don\\'t think this is the case'\n",
        "\t).\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Edge case: repeating statements in proofs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The modifications of `explain_question` also required dealing with this edge\n",
        "case: when proving \"some humans win\", the `prove_rb` predicate will first\n",
        "prove `human(sk)` using the rule \"some humans are geniuses\"\n",
        "(i.e. `[(human(sk):-true),(genius(sk):-true)]`), then prove `win(sk)`\n",
        "using the rule \"all geniuses win\" (i.e. `win(X):-genius(X)`) combined with\n",
        "\"some humans are geniuses\" (i.e.`[(human(sk):-true),(genius(sk):-true)]`).\n",
        "Note that \"some humans are geniuses\" is used twice in the proof, leading to\n",
        "reasoning such as\n",
        "> some humans are geniuses; every genius wins; some humans are geniuses; therefore some humans win\n",
        "\n",
        "While this is technically sound reasoning, having the same statement appear\n",
        "twice is inelegant, which is why I decided to remove duplicates:\n",
        "```prolog\n",
        "explain_question(Query,SessionId,Answer):-\n",
        "\tfindall(R,prolexa:stored_rule(SessionId,R),Rulebase),\n",
        "\t( prove_rb(Query,Rulebase,[],Proof) ->\n",
        "\t\tmaplist(pstep2message,Proof,Msg),\n",
        "\t\tremove_duplicates(Msg,MsgNoDups),\n",
        "\t\t(\n",
        "\t\t\tQuery = (Q1,Q2), phrase(sentence1([(Q1:-true),(Q2:-true)]),L)\n",
        "\t\t\t; Query \\= (_,_), phrase(sentence1([(Query:-true)]),L)\n",
        "\t\t),\n",
        "\t\tatomic_list_concat([therefore|L],\" \",Last),\n",
        "\t\tappend(MsgNoDups,[Last],Messages),\n",
        "\t\tatomic_list_concat(Messages,\"; \",Answer)\n",
        "\t; Answer = 'Sorry, I don\\'t think this is the case'\n",
        "\t).\n",
        "\n",
        "\n",
        "remove_duplicates([], []).\n",
        "remove_duplicates([H|T], List) :- member(H, T), !, remove_duplicates(T, List).\n",
        "remove_duplicates([H|T1], [H|T2]) :- remove_duplicates(T1, T2).\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Demo of existential quantification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prolexa(\"forget everything\")\n",
        "prolexa(\"all geniuses win\")\n",
        "prolexa(\"some humans are geniuses\")\n",
        "prolexa(\"explain why some humans win\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Open-ended demo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is an open-ended interactive demo where you can explore these new capabilities (the code is taken from [the demo notebook in the original repo](https://colab.research.google.com/github/simply-logical/ComputationalLogic/blob/prolexa-plus/Prolexa_Plus_Demo_Notebook.ipynb#scrollTo=HDY7hKs490UH)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from ipywidgets import Layout\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "w_textbox = widgets.Textarea(\n",
        "    value = 'tell me about Peter',\n",
        "    placeholder='Input text',\n",
        "    description='Question:',\n",
        "    layout=Layout(width='900px', height='50px')\n",
        ")\n",
        "w_button = widgets.Button(\n",
        "    description='Ask',\n",
        "    button_style='info',\n",
        "    layout=Layout(margin='4px 0px 0px 90px')\n",
        ")\n",
        "w_out = widgets.Output(layout={'border': '1px solid black'})\n",
        "\n",
        "\n",
        "def main(obj):\n",
        "    query = w_textbox.value.strip()\n",
        "    answer = meta.standardised_query(pl, query)[0]['Output']\n",
        "    with w_out:\n",
        "        print('?', query)\n",
        "        print(answer)\n",
        "\n",
        "# bind event handler to UI control\n",
        "w_button.on_click(main)\n",
        "# render UI controls in a vertical box\n",
        "widgets.VBox([w_textbox, w_button, w_out])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Work in progress: extending grammar to handle complex conjunctions and disjunctions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I originally intended to extend Prolexa's reasoning much further by completely\n",
        "re-thinking the way `prolexa_grammar` works. I wanted Prolexa to handle arbitrarily\n",
        "complex conjunctive and disjunctive statements, for instance:\n",
        "> everyone who is either the not the messiah or a very naughty boy is not blessed and not a cheesemaker.\n",
        "\n",
        "This could be used, among other things, for disjunctive reasoning such as this:\n",
        "> every blessed person is either a messiah or a cheesemaker;\n",
        "> brian is not a messiah; brian is blessed; therefore, brian is a cheesemaker\n",
        "\n",
        "In order to do this, I decided to completely refactor much of the code base,\n",
        "but got stuck on one particular predicate and decided to abandon these efforts.\n",
        "\n",
        "![](https://pbs.twimg.com/media/CpIlMEdVUAQlhIW?format=jpg&name=medium)\n",
        "\n",
        "Nontheless, most of the refactoring is complete and I want to explain my\n",
        "approach to it in this section. You can find the code on the\n",
        "[`multi-meaning` branch](https://github.com/lucyfarnik/ComputationalLogic/tree/multi-meaning).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### High-level approach\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The core idea here is to refactor the code base such that each sentence\n",
        "consists of 2 parts, a noun phrase and a verb phrase, each of which can\n",
        "have multiple \"meanings\". For example \"everyone who is a naughty boy\n",
        "is not the messiah and is not blessed\" has the noun phrase meanings\n",
        "`[naughty, boy]` and the verb phrase meanings `[not(messiah), not(blessed)]`.\n",
        "Since the noun phrase is universally quantified, this gets translated into\n",
        "the clauses `[(not(messiah(X)) :- naughty(X),boy(X)), (not(blessed(X)) :- naughty(X),boy(X))]`.\n",
        "Note that this means that a single sentence can encode arbitrarily many clauses.\n",
        "\n",
        "In order to handle disjunction, we use the fact that $A\\implies B\\lor C$ is\n",
        "equivalent to $(A\\land\\lnot C\\implies B)\\land(A\\land\\lnot B\\implies C)$\n",
        "(see [Chapter 2.4 of Simply Logical](https://book.simply-logical.space/src/text/1_part_i/2.4.html) for details).\n",
        "This meant that a sentence like \"every blessed person is either a messiah or a cheesemaker\"\n",
        "would have the noun phrase meanings `[blessed, person]` and the verb phrase\n",
        "meanings `[disjunction(messiah, cheesemaker)]`, which would get translated to\n",
        "the clauses `[(messiah(X):-blessed(X),person(X),not(cheesemaker(X))), (cheesemaker(X):-blessed(X),person(X),not(messiah(X)))]`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Allowing sentences to encode arbitrarily many meanings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "First, this required modifying the root-level module `prolexa.pl` to\n",
        "take into accound sentences whose arguments are lists of arbitrarily many\n",
        "clauses. This was done by modifying the part of `handle_utterance` that\n",
        "deals with sentences:\n",
        "```prolog\n",
        "% A. Utterance is a sentence \n",
        "\t( phrase(sentence(Rules),UtteranceList),\n",
        "\t  write_debug(rule(Rules)),\n",
        "\t  (\n",
        "\t\tall_known_rules(Rules,SessionId) -> % A1. All rules are known\n",
        "\t\t\tatomic_list_concat(['I already knew that',Utterance],' ',Answer)\n",
        "\t\t; otherwise -> %A2. At least one rule is new\n",
        "\t\t\tstore_new_rules(Rules,SessionId),\n",
        "\t\t\tatomic_list_concat(['I will remember that',Utterance],' ',Answer)\n",
        "\t  )\n",
        "```\n",
        "where `all_known_rules` and `store_new_rules` are defined as\n",
        "```prolog\n",
        "store_new_rules([], _).\n",
        "store_new_rules([Rule|Rest], SessionId):-\n",
        "\t(known_rule([Rule],SessionId) -> true\n",
        "\t; otherwise -> assertz(prolexa:stored_rule(SessionId,[Rule]))),\n",
        "\tstore_new_rules(Rest, SessionId).\n",
        "\n",
        "all_known_rules([],_).\n",
        "all_known_rules([Rule|Rest],SessionId) :-\n",
        "\tknown_rule([Rule],SessionId), all_known_rules(Rest,SessionId).\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Refactoring sentence structure\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Sentences are now defined simply as\n",
        "```prolog\n",
        "sentence(Clauses) --> \n",
        "\ttop_level_noun_phrase(Number, Quantifier, NounPhraseMeanings),\n",
        "\tverb_phrase(Number, VerbPhraseMeanings),\n",
        "\t{clauses_to_meanings(Clauses, Quantifier,\n",
        "\t\tNounPhraseMeanings, VerbPhraseMeanings)}.\n",
        "```\n",
        "\n",
        "The top-level noun phrase can be either a list of proper nouns, or a determiner\n",
        "followed by a regular noun phrase\n",
        "```prolog\n",
        "% the highest-level noun phrase in the parse tree (the one whose parent is the sentence)\n",
        "top_level_noun_phrase(Number, no_quantifier, Meanings) -->\n",
        "\tproper_nouns(Number, Meanings).\n",
        "top_level_noun_phrase(Number, Quantifier, Meanings) -->\n",
        "\t% IsNounPhraseComplex means that we have to list multiple properties\n",
        "\t% eg \"everyone who is a human and flies\" is complex while \"every human\" isn't\n",
        "\tdeterminer(Number, IsNounPhraseComplex, Quantifier),\n",
        "\tnoun_phrase(Number, IsNounPhraseComplex, Meanings).\n",
        "\n",
        "% may be a single plural noun or multiple of them\n",
        "proper_nouns(singular, [Meaning]) --> proper_noun(Meaning).\n",
        "proper_nouns(plural, Meanings) --> proper_nouns1(Meanings).\n",
        "\n",
        "% multiple plural nouns\n",
        "proper_nouns1([Meaning, Meaning2]) -->\n",
        "\tproper_noun(Meaning), [and], proper_noun(Meaning2).\n",
        "proper_nouns1([Meaning|Meanings]) -->\n",
        "\tproper_noun(Meaning), [','], proper_nouns1(Meanings).\n",
        "\n",
        "determiner(singular, simple, universal_quantifier) --> [every].\n",
        "determiner(plural, simple, universal_quantifier) --> [all].\n",
        "determiner(singular, complex, universal_quantifier) --> [everyone, who].\n",
        "\n",
        "% noun_phrase(singular,M) --> [a],noun_phrase(singular,M).\n",
        "noun_phrase(Number, simple, [Meaning]) --> noun(Number,Meaning).\n",
        "noun_phrase(Number, simple, [Meaning1, Meaning2]) --> \n",
        "\tdegree, adjective(Meaning1), noun(Number,Meaning2).\n",
        "% noun_phrase(Number, simple, not(Meaning)) --> ['non-'], noun(Number, Meaning).\n",
        "noun_phrase(Number, complex, Meanings) --> properties(Number, Meanings).\n",
        "\n",
        "degree --> []|[very]|[vewy]. % for now, this carries no semantics\n",
        "```\n",
        "\n",
        "The verb phrase is simply a list of properties, much like the noun phrase:\n",
        "```prolog\n",
        "verb_phrase(Number, Meanings) --> properties(Number, Meanings).\n",
        "```\n",
        "\n",
        "Properties can be conjunctively or disjunctively connected (or certain\n",
        "combinations of the two):\n",
        "```prolog\n",
        "properties(Number, Meanings) --> property(Number, Meanings).\n",
        "properties(Number, Meanings) --> \n",
        "\tproperty(Number, Meanings1), [and], property(Number, Meanings2),\n",
        "\t{append(Meanings1, Meanings2, Meanings)}.\n",
        "properties(Number, [Meaning|Meanings]) --> \n",
        "\tproperty(Number, [Meaning]), [','], properties(Number, Meanings).\n",
        "\n",
        "% `property` is defined in a nested way where each layer processes\n",
        "% a different part of the sequence\n",
        "% note that `property` can have 2 meanings because \"a mortal human\" is\n",
        "% parsed as 1 property even though it has 2 meanings\n",
        "% the top-level property predicate processes disjunctions\n",
        "property(Number, Meanings) --> property1(Number, Meanings).\n",
        "property(Number, [disjunction(Meaning1, Meaning2)]) -->\n",
        "\t([either] | []), property1(Number, Meaning1), [or], property1(Number, Meaning2).\n",
        "\n",
        "% property1 processes verbs (incl. the verb \"to be\")\n",
        "property1(Number, [Meaning]) --> iverb(Number, Meaning).\n",
        "property1(Number, [NegatedMeaning]) -->\n",
        "\tverb_negation(Number), iverb(Number, Meaning), {negate(Meaning, NegatedMeaning)}.\n",
        "property1(singular, Meanings) --> [is], property2(singular, Meanings).\n",
        "property1(plural, Meanings) --> [are], property2(plural, Meanings).\n",
        "\n",
        "verb_negation(singular) --> [does,not] | ['doesn\\'t'].\n",
        "verb_negation(plural) --> [do,not] | ['don\\'t'].\n",
        "\n",
        "% property2 processes negation\n",
        "property2(Number, Meanings) --> property3(Number, Meanings).\n",
        "property2(Number, NegatedMeanings) -->\n",
        "\t[not], property3(Number, Meanings),\n",
        "\t{negate_all(Meanings, NegatedMeanings)}.\n",
        "\n",
        "% property3 fully processes properties which do not include a noun;\n",
        "% for properties which do include a noun, it processes \"a\" or \"the\"\n",
        "property3(_, [Meaning]) --> degree, adjective(Meaning).\n",
        "property3(singular, Meanings) --> ([a] | [the]), property4(singular, Meanings).\n",
        "property3(plural, Meanings) --> ([] | [the]), property4(plural, Meanings).\n",
        "\n",
        "% property4 fully processes properties which include a noun\n",
        "property4(Number, [Meaning]) --> noun(Number, Meaning).\n",
        "property4(Number, [Meaning1, Meaning2]) --> \n",
        "\tdegree, adjective(Meaning1), noun(Number, Meaning2).\n",
        "\n",
        "negate(not(X), X).\n",
        "negate(X, not(X)).\n",
        "\n",
        "negate_all([], []).\n",
        "negate_all([Meaning|Meanings], [NegatedMeaning|NegatedMeanings]) :-\n",
        "\tnegate(Meaning, NegatedMeaning),\n",
        "\tnegate_all(Meanings, NegatedMeanings).\n",
        "```\n",
        "\n",
        "We define parts of speech similarly to how they are defined\n",
        "in the original code base, except we get rid of the `=>` operator:\n",
        "```prolog\n",
        "adjective(Meaning)\t\t--> [Adj],    {meaning_to_word(Meaning,1,a/Adj)}.\n",
        "% adjective(not(M))\t--> [Adj_neg],{meaning_to_word(_P,1,a/Adj_pos, M),adj_pos2neg(Adj_pos,Adj_neg)}.\n",
        "% adjective(not(M))\t--> [Adj_pos],{meaning_to_word(_P,1,a/Adj_neg, M),adj_pos2neg(Adj_pos,Adj_neg)}.\n",
        "noun(singular, Meaning)\t--> [Noun],   {meaning_to_word(Meaning,1,n/Noun)}.\n",
        "noun(plural, Meaning)\t--> [Noun_p], {meaning_to_word(Meaning,1,n/Noun), noun_s2p(Noun,Noun_p)}.\n",
        "iverb(singular, Meaning)--> [Verb_s], {meaning_to_word(Meaning,1,v/Verb), verb_p2s(Verb,Verb_s)}.\n",
        "iverb(plural, Meaning)\t--> [Verb],   {meaning_to_word(Meaning,1,v/Verb)}.\n",
        "\n",
        "meaning_to_word(Meaning,1,Class/Word):-\n",
        "\tpred(Meaning, 1, Literals),\n",
        "\tmember(Class/Word, Literals).\n",
        "```\n",
        "\n",
        "Lastly, the vocabulary I'm using throughout this section is defined as:\n",
        "```prolog\n",
        "% unary predicates for adjectives, nouns, and verbs\n",
        "pred(messiah, 1,[n/messiah]).\n",
        "pred(naughty, 1,[a/naughty]).\n",
        "pred(boy,     1,[n/boy]).\n",
        "pred(blessed, 1,[a/blessed]).\n",
        "pred(cheesemaker, 1, [n/cheesemaker]).\n",
        "pred(released, 1,[a/released,a/weleased]).\n",
        "\n",
        "% proper nouns\n",
        "proper_noun(brian) --> [brian]|[bwian].\n",
        "proper_noun(roger) --> [roger]|[woger].\n",
        "```\n",
        "(Note the additional accesibility feature of allowing users with speech\n",
        "sound disorders (namely rhotacism) to still use the software, for instance\n",
        "\"woger is weleased\" is correctly interpreted to be the same as \"roger is released\".)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Converting between clauses and meanings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The part of this refactoring which I ultimately did not finish is the predicate\n",
        "`clauses_to_meanings`, which expresses the afforementioned relation between clauses,\n",
        "noun phrase meanings, and verb phrase meanings.\n",
        "\n",
        "(Note: I initially tried a different approach to implementing this; this can\n",
        "still be found in `prolexa_grammar` and is currently commented out.)\n",
        "\n",
        "```prolog\n",
        "%%% semantic processing %%%\n",
        "% converts between Prolog clauses and the meanings of noun phrases and verb phrases\n",
        "% usage: clauses_to_meanings(Clauses, Quantifier, NounPhraseMeanings, VerbPhraseMeanings)\n",
        "clauses_to_meanings([], _, [], _). % base case: no more noun phrase meanings\n",
        "clauses_to_meanings([], _, _, []). % base case: no more verb phrase meanings\n",
        "\n",
        "clauses_to_meanings([Clause1,Clause2|ClausesRest], no_quantifier, [NounPhraseM],\n",
        "\t\t\t\t\t[disjunction(VerbPhraseM1,VerbPhraseM2)|VerbPhraseRest]) :-\n",
        "\t % if we have a disjunction, we need to process it separately\n",
        "\t((nonvar(VerbPhraseM1), nonvar(VerbPhraseM2)) -> !\n",
        "\t; otherwise -> true),\n",
        "\tClause1 = (ClauseHead1:-NegatedClauseHead2),\n",
        "\tClause2 = (ClauseHead2:-NegatedClauseHead1),\n",
        "\tnegate(ClauseHead1, NegatedClauseHead1),\n",
        "\tnegate(ClauseHead2, NegatedClauseHead2),\n",
        "\tuniv_with_negation(VerbPhraseM1, NounPhraseM, ClauseHead1),\n",
        "\tuniv_with_negation(VerbPhraseM2, NounPhraseM, ClauseHead2),\n",
        "\tclauses_to_meanings(ClausesRest, no_quantifier, [NounPhraseM], VerbPhraseRest).\n",
        "clauses_to_meanings([Clause|ClausesRest], no_quantifier, [NounPhraseM], [VerbPhraseM|VerbPhraseRest]) :- \n",
        "\tClause = (ClauseHead:-true),\n",
        "\tuniv_with_negation(VerbPhraseM, NounPhraseM, ClauseHead),\n",
        "\tclauses_to_meanings(ClausesRest, no_quantifier, [NounPhraseM], VerbPhraseRest).\n",
        "clauses_to_meanings(Clauses, no_quantifier, [NounPhraseM|NounPhraseRest], VerbPhraseMeanings) :-\n",
        "\tappend(Clauses1, Clauses2, Clauses), %! this clause leads to stack overflow rn\n",
        "\tclauses_to_meanings(Clauses1, no_quantifier, [NounPhraseM], VerbPhraseMeanings),\n",
        "\tclauses_to_meanings(Clauses2, no_quantifier, NounPhraseRest, VerbPhraseMeanings).\n",
        "\n",
        "\n",
        "clauses_to_meanings([Clause1, Clause2|ClausesRest], universal_quantifier, NounPhraseMeanings,\n",
        "\t[disjunction(VerbPhraseM1,VerbPhraseM2)|VerbPhraseRest]) :-\n",
        "\t % if we have a disjunction, we need to process it separately\n",
        "\t((nonvar(VerbPhraseM1), nonvar(VerbPhraseM2)) -> !\n",
        "\t; otherwise -> true),\n",
        "\tClause1 = (ClauseHead1:-(ClauseBody,NegatedClauseHead2)),\n",
        "\tClause2 = (ClauseHead2:-(ClauseBody,NegatedClauseHead1)),\n",
        "\tnegate(ClauseHead1, NegatedClauseHead1),\n",
        "\tnegate(ClauseHead2, NegatedClauseHead2),\n",
        "\tuniv_with_negation(VerbPhraseM1, X, ClauseHead1),\n",
        "\tuniv_with_negation(VerbPhraseM2, X, ClauseHead2),\n",
        "\tconjunction_to_terms(NounPhraseMeanings, ClauseBody, X),\n",
        "\tclauses_to_meanings(ClausesRest, universal_quantifier, NounPhraseMeanings, VerbPhraseRest).\n",
        "clauses_to_meanings([Clause|ClauseRest], universal_quantifier, NounPhraseMeanings, [VerbPhraseM|VerbPhraseRest]) :-\n",
        "\tClause = (ClauseHead:-ClauseBody),\n",
        "\tuniv_with_negation(VerbPhraseM, X, ClauseHead),\n",
        "\tconjunction_to_terms(NounPhraseMeanings, ClauseBody, X),\n",
        "\tclauses_to_meanings(ClauseRest, universal_quantifier, NounPhraseMeanings, VerbPhraseRest).\n",
        "\n",
        "% the equivalent of the '(=..)/2' operator except it can also take\n",
        "% not(functor) as the first argument\n",
        "univ_with_negation(not(Functor), Arg, not(Term)) :-\n",
        "\t!,\n",
        "\tTerm =.. [Functor, Arg].\n",
        "univ_with_negation(Functor, Arg, Term) :-\n",
        "\tTerm =.. [Functor, Arg].\n",
        "\n",
        "% turn an arbitrarily long conjunction into a list of terms\n",
        "% usage: conjunction_to_terms(Meanings, Terms, X)\n",
        "% example: conjunction_to_terms([human, flies], [human(X), flies(X)], X)\n",
        "conjunction_to_terms([], true, _).\n",
        "conjunction_to_terms([Meaning], Term, X) :-\n",
        "\t!,\n",
        "\tuniv_with_negation(Meaning, X, Term).\n",
        "conjunction_to_terms([Meaning|MeaningsRest], Terms, X) :-\n",
        "\tTerms = (Term,TermsRest),\n",
        "\tuniv_with_negation(Meaning, X, Term),\n",
        "\tconjunction_to_terms(conjunction(MeaningsRest), TermsRest, X).\n",
        "\n",
        "```\n",
        "\n",
        "Ultimately, this ended up being much more complex than anticipated due to a\n",
        "mix of insufficient instantiation errors when applying predicates \"in the\n",
        "other direction\", out of memory errors due to issues with the recursion,\n",
        "and various other things."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Prolexa Plus Demo Notebook.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c965e705b494f7e8cdb6d02cc5a6553": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7c763c143f9043b39a5af860c2d79d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "info",
            "description": "Ask",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d35477f4aa2d46009151e655c32ef9b2",
            "style": "IPY_MODEL_5c965e705b494f7e8cdb6d02cc5a6553",
            "tooltip": ""
          }
        },
        "866eb75519134b6d8298aeda3b02c808": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": "1px solid black",
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8811264ce4e74e13830181ed911d0aad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9b6c304e9f2644baadd7c52699f97f4b",
              "IPY_MODEL_7c763c143f9043b39a5af860c2d79d23",
              "IPY_MODEL_f66f034025314913a5bac66234e33df2"
            ],
            "layout": "IPY_MODEL_b047630437e845c1887c418669785c5c"
          }
        },
        "9b6c304e9f2644baadd7c52699f97f4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextareaModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Question:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_baf12de9a3644fc1a7fdd32395a9efbd",
            "placeholder": "Input text",
            "rows": null,
            "style": "IPY_MODEL_d82d12f6a0a249e5a5750af18cbc020e",
            "value": "tell me about Peter"
          }
        },
        "b047630437e845c1887c418669785c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baf12de9a3644fc1a7fdd32395a9efbd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "50px",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "900px"
          }
        },
        "d35477f4aa2d46009151e655c32ef9b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "4px 0px 0px 90px",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82d12f6a0a249e5a5750af18cbc020e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f66f034025314913a5bac66234e33df2": {
          "model_module": "@jupyter-widgets/output",
          "model_module_version": "1.0.0",
          "model_name": "OutputModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_866eb75519134b6d8298aeda3b02c808",
            "msg_id": "",
            "outputs": [
              {
                "name": "stdout",
                "output_type": "stream",
                "text": [
                  "? tell me about Peter\n",
                  "peter is human. peter is mortal. peter is a professor. peter is a teacher\n"
                ]
              }
            ]
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
